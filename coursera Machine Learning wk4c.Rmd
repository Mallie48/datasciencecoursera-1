---
title: "Coursera Machine Learning Assignment"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = FALSE, include = FALSE)
```

Load the source data and packages needed 
```{r}
library(caret)
library(rpart)
library(AppliedPredictiveModeling)
library(ElemStatLearn)
library(pgmm)
library(ggplot2)

training<-read.csv("~/pml-training.csv")

head(training)
tail(training)
str(training)
str(training$classe)

```
Convert the response variable to a factor 

```{r}
training$classe<-as.factor(training$classe)
```
Check there are no missings in the response. 
```{r}
table(training$classe)
```
Review the dataset by eye 
```{r}

fix(training)
```

By eye you can see columns mainly populated with NA - Kurtosis, Skew. 
Dataset instructions were clear on the sensors - find the variables needed and this was done by reviewing the 
output of fix. 

```{r}
traincut<-subset(training,select=c(roll_belt:total_accel_belt,
                               gyros_belt_x:total_accel_arm,
                               gyros_arm_x:magnet_arm_z,
                               roll_dumbbell:yaw_dumbbell,
                               total_accel_dumbbell,
                               gyros_dumbbell_x:yaw_forearm,
                               total_accel_forearm,
                               gyros_forearm_x:classe
                               
                               ))

```
Model using random forest rather than a probably overfitted classification tree
USe 10 fold cross validation. Subset our training data though to assess our fit

```{r}
ctrl <- trainControl(method="cv",number=10,verboseIter = TRUE)
set.seed(13208)

inTrain <- createDataPartition(y = traincut$classe, p = .80, list = FALSE)
traincutp<-traincut[inTrain,]
traincutt<-traincut[-inTrain,]

```
Fit a Random forest - this ws the code used
```{r}

model4<-train(classe~.,data=traincutp,method="rf",trControl = ctrl)
pred4<-predict(model4,traincutp)
```



Assess the fit on the training data (subset)
```{r}
table(traincutp$classe,pred4)
```
 pred4
       A    B    C    D    E
  A 4464    0    0    0    0
  B    0 3038    0    0    0
  C    0    0 2738    0    0
  D    0    0    0 2573    0
  E    0    0    0    0 2886
This looks pretty good - now try the accuracy on the  hold out sample
```{r}
pred4t<-predict(model4,traincutt)
table(traincutt$classe,pred4t)

```
  pred4t
       A    B    C    D    E
  A 1116    0    0    0    0
  B    0  758    1    0    0
  C    0    0  684    0    0
  D    0    0    0  643    0
  E    1    0    0    2  718
Now lets test accuracy on the Training and Test dataset. 
Training data

This shows the accuracy to be 100% on the training dataset. 
THe Out of Sample Error fitting the model on the hold out sample is 1-0.9954 or <0.5%. 
```{r}
confusionMatrix(pred4,traincutp$classe)
```
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 4464    0    0    0    0
         B    0 3038    0    0    0
         C    0    0 2738    0    0
         D    0    0    0 2573    0
         E    0    0    0    0 2886

Overall Statistics
                                     
               Accuracy : 1          
                 95% CI : (0.9998, 1)
    No Information Rate : 0.2843     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   1.0000   1.0000   1.0000   1.0000
Specificity            1.0000   1.0000   1.0000   1.0000   1.0000
Pos Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
Neg Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2843   0.1935   0.1744   0.1639   0.1838
Detection Prevalence   0.2843   0.1935   0.1744   0.1639   0.1838
Balanced Accuracy      1.0000   1.0000   1.0000   1.0000   1.0000
A perfect fit . ..potential overfitting but lets see . . 

```{r}
confusionMatrix(pred4t,traincutt$classe)
```

Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1116    1    0    0    2
         B    0  757    1    0    0
         C    0    1  681    8    0
         D    0    0    2  635    3
         E    0    0    0    0  716

Overall Statistics
                                          
               Accuracy : 0.9954          
                 95% CI : (0.9928, 0.9973)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9942          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   0.9974   0.9956   0.9876   0.9931
Specificity            0.9989   0.9997   0.9972   0.9985   1.0000
Pos Pred Value         0.9973   0.9987   0.9870   0.9922   1.0000
Neg Pred Value         1.0000   0.9994   0.9991   0.9976   0.9984
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2845   0.1930   0.1736   0.1619   0.1825
Detection Prevalence   0.2852   0.1932   0.1759   0.1631   0.1825
Balanced Accuracy      0.9995   0.9985   0.9964   0.9930   0.9965
That is an acceptable level of accuracy >99% and suggests overfitting is not an issue. 

Now lets gather the Test data and predict the values. 


```{r}
testing<-read.csv("~/pml-testing.csv")
```
Fit the model

```{r}
Prediction<-predict(model4,testing)
testing$Prediction<-Prediction
```
Submit answers
```{r}
Answer<-subset(testing,select=c(problem_id:Prediction))
Answer
```

1  	B		
2  	A		
3  	B		
4	  A		
5	  A		
6 	E		
7	  D		
8  	B		
9	  A		
10	A
11	B		
12	C		
13	B		
14	A		
15	E		
16	E		
17	A		
18	B		
19	B		
20	B

